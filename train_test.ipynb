{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, Subset\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from CustomAccuracyMetrics import get_cycle_penalty_max_offpath, get_cycle_penalty\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from itertools import product\n",
    "from CustDataset import CustDataset\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import CustomAccuracyMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root = f\"/home/narehman_l/test_{datetime.now().strftime(\"%Y.%m.%d_%H.%M.%S\")}\"\n",
    "os.mkdir(test_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_off_path = {\n",
    "    'clang': 49.544,\n",
    "    'gcc' : 35.391,\n",
    "    'mysql' : 11.846,\n",
    "    'mongodb' : 13.896,\n",
    "    'postgres' : 20.575,\n",
    "    'verilator' : 19.353,\n",
    "    'postgres' : 139.567\n",
    "}\n",
    "\n",
    "cycles = [\n",
    "    9566632.0,\n",
    "    11505414.0,\n",
    "    10004884.0,\n",
    "    12326291.0,\n",
    "    7771614.0,\n",
    "    35282687.0,\n",
    "    497644239.0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [512]\n",
    "ns = [48]\n",
    "pentalty_weights = [0.001]\n",
    "hidden_size_0s = [512]\n",
    "hidden_size_1s = [256]\n",
    "hidden_size_2s = [64]\n",
    "downsample_factor = [10]\n",
    "feature_lists = [[\n",
    "    'ft_start_addr', \n",
    "    'ft_length', \n",
    "    'ft_ended_by',\n",
    "    'cycles_since_btb_rec', \n",
    "    'cycles_since_ibtb_rec',\n",
    "    'cycles_since_misfetch_rec', \n",
    "    'cycles_since_mispred_rec',\n",
    "    'btb_miss_rate', \n",
    "    'ibtb_miss_rate', \n",
    "    'misfetch_rate', \n",
    "    'mispred_rate',\n",
    "    'cf_mask', \n",
    "    'tage_comp_base', \n",
    "    'tage_comp_short', \n",
    "    'tage_comp_long',\n",
    "    'tage_comp_loop', \n",
    "    'tage_comp_sc'\n",
    "]]\n",
    "strides = [\n",
    "    2,\n",
    "    4,\n",
    "    8,\n",
    "    12,\n",
    "]\n",
    "num_epochs = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = product(batch_sizes,\n",
    "                    ns,\n",
    "                    pentalty_weights,\n",
    "                    hidden_size_0s,\n",
    "                    hidden_size_1s,\n",
    "                    hidden_size_2s,\n",
    "                    downsample_factor,\n",
    "                    feature_lists,\n",
    "                    strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Feed_Forward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_0, hidden_size_1, hidden_size_2, output_size):\n",
    "        super(Feed_Forward, self).__init__()\n",
    "\n",
    "        self.hidden_size_0 = hidden_size_0\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "\n",
    "        self.i2h0 = nn.Linear(input_size, hidden_size_0)\n",
    "        self.h02h1 = nn.Linear(hidden_size_0, hidden_size_1)\n",
    "        self.h12h2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.h22o = nn.Linear(hidden_size_2, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = F.relu(self.i2h0(input))\n",
    "        output = F.relu(self.h02h1(output))\n",
    "        output = F.relu(self.h12h2(output))\n",
    "        output = F.sigmoid(self.h22o(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    print(config)\n",
    "    batch_size      = config[0]\n",
    "    n               = config[1]\n",
    "    penalty_weight  = config[2]\n",
    "    hidden_size_0   = config[3]\n",
    "    hidden_size_1   = config[4]\n",
    "    hidden_size_2   = config[5]\n",
    "    downsample_factor = config[6]\n",
    "    feature_list    = config[7]\n",
    "    stride          = config[8]\n",
    "\n",
    "    # write out configuration\n",
    "    test_path = test_root + f\"/config_{i}\"\n",
    "    print(test_path)\n",
    "    os.mkdir(test_path)\n",
    "    with open(test_path + '/config.txt', 'w') as config_file:\n",
    "        config_file.write(f'batch_size: {batch_size}')\n",
    "        config_file.write(f'n: {n}')\n",
    "        config_file.write(f'penalty_weight: {penalty_weight}\\n')\n",
    "        config_file.write(f'hidden_size_0: {hidden_size_0}\\n')\n",
    "        config_file.write(f'hidden_size_2: {hidden_size_2}\\n')\n",
    "        config_file.write(f'downsample_factor: {downsample_factor}\\n')\n",
    "        config_file.write(f'feature_list: {feature_list}\\n')\n",
    "        config_file.write(f'stride: {stride}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "train_feather_files = [f'/home/narehman_l/10_21_2024_ml/icache_consumed_chunked_data/{file_id}.feather' for file_id in range(0, 4183)]\n",
    "dataset = CustDataset(train_feather_files, n, stride, feature_list, penalty_weight)\n",
    "\n",
    "train_loader, workload_test_sets = utils.get_train_loader(dataset, \n",
    "                                                            '/home/narehman_l/10_21_2024_ml/icache_consumed_chunked_data/train_test_idxs.json',\n",
    "                                                            batch_size,\n",
    "                                                            num_workers=0)\n",
    "\n",
    "feed_forward_model = Feed_Forward(input_size=(len(feature_list) * n), hidden_size_0=hidden_size_0, hidden_size_1=hidden_size_1, hidden_size_2=hidden_size_2, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[800][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(feed_forward_model.parameters(), lr=0.00005)\n",
    "\n",
    "loss_values = utils.train_model(feed_forward_model, criterion, optimizer, test_path, device, train_loader, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_losses(loss_values, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = utils.test_model(feed_forward_model, dataset, workload_test_sets, test_path, device, batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = CustomAccuracyMetrics.get_metrics(predictions_df, predictions_df, avg_off_path, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_df['custom_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maxwell_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
